{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bLc7z55pOt5n",
        "outputId": "d978df6e-6098-43bc-803c-fb06ffb1629d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1xi7zilOJ8qxZgm5vLVjheVKziOfwqiIw\n",
            "To: /content/train_df.xlsx\n",
            "100% 2.14M/2.14M [00:00<00:00, 196MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1ppJhP-wunCc69GTLA9Yc8jXPlHcjYo_l\n",
            "To: /content/test_df.xlsx\n",
            "100% 889k/889k [00:00<00:00, 159MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Aj4olw8KDH7NrKFLQZeSN_Hfxj8d4uuT\n",
            "To: /content/stopwords.txt\n",
            "100% 7.86k/7.86k [00:00<00:00, 23.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1cDHLwy0ZgNxWN5nvCvqWWPNyLwMP1A0d\n",
            "To: /content/dict.txt\n",
            "100% 1.17k/1.17k [00:00<00:00, 6.35MB/s]\n"
          ]
        }
      ],
      "source": [
        "!gdown --fuzzy \"https://docs.google.com/spreadsheets/d/1xi7zilOJ8qxZgm5vLVjheVKziOfwqiIw/edit?usp=drive_link&ouid=103889639646613430352&rtpof=true&sd=true\" -O train_df.xlsx\n",
        "!gdown --fuzzy \"https://docs.google.com/spreadsheets/d/1ppJhP-wunCc69GTLA9Yc8jXPlHcjYo_l/edit?usp=drive_link&ouid=103889639646613430352&rtpof=true&sd=true\" -O test_df.xlsx\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1Aj4olw8KDH7NrKFLQZeSN_Hfxj8d4uuT/view?usp=drive_link\" -O stopwords.txt\n",
        "!gdown --fuzzy \"https://drive.google.com/file/d/1cDHLwy0ZgNxWN5nvCvqWWPNyLwMP1A0d/view?usp=drive_link\" -O dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openpyxl\n",
        "!pip install jieba\n",
        "!pip install opencc\n",
        "!pip install keras_nlp"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v70zZTQIP71t",
        "outputId": "08e0cc8f-764c-4436-c8a1-acc748122db2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (1.1.0)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (0.42.1)\n",
            "Requirement already satisfied: opencc in /usr/local/lib/python3.10/dist-packages (1.1.7)\n",
            "Requirement already satisfied: keras_nlp in /usr/local/lib/python3.10/dist-packages (0.11.1)\n",
            "Requirement already satisfied: keras-core in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.7)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (24.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2023.12.25)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (13.7.1)\n",
            "Requirement already satisfied: dm-tree in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.1.8)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (0.2.5)\n",
            "Requirement already satisfied: tensorflow-text in /usr/local/lib/python3.10/dist-packages (from keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kagglehub->keras_nlp) (4.66.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-core->keras_nlp) (3.11.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: tensorflow<2.17,>=2.16.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text->keras_nlp) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras_nlp) (0.1.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.3.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (4.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (1.14.1)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (1.63.0)\n",
            "Requirement already satisfied: tensorboard<2.17,>=2.16 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (2.16.2)\n",
            "Requirement already satisfied: keras>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (3.3.3)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.37.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->kagglehub->keras_nlp) (2024.2.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.43.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.11.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16.1->tensorflow-text->keras_nlp) (2.1.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "from typing import List\n",
        "from pprint import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from opencc import OpenCC\n",
        "import jieba\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "4M_c1AKMPg_M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_excel(\"train_df.xlsx\")\n",
        "test_df = pd.read_excel(\"test_df.xlsx\")\n",
        "\n",
        "train_df['text'] = train_df['text'].apply(lambda x: str(x))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: str(x))\n",
        "\n",
        "train_df = train_df[['index', 'text', 'score']]\n",
        "test_df = test_df[['index', 'text']]"
      ],
      "metadata": {
        "id": "C6_8AjqlQMmT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df, dev_df = train_test_split(train_df,\n",
        "                                    test_size=0.2,\n",
        "                                    stratify=train_df['score'],\n",
        "                                    random_state=42)"
      ],
      "metadata": {
        "id": "hQaAlMYCVBDp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cc = OpenCC('s2t')\n",
        "train_df['text'] = train_df['text'].apply(lambda x: cc.convert(x))\n",
        "test_df['text'] = test_df['text'].apply(lambda x: cc.convert(x))\n",
        "dev_df['text'] = dev_df['text'].apply(lambda x: cc.convert(x))\n",
        "\n",
        "jieba.initialize()\n",
        "jieba.load_userdict('dict.txt')\n",
        "\n",
        "train_df['ckip_ws'] = train_df['text'].apply(lambda x: jieba.lcut(x))\n",
        "test_df['ckip_ws'] = test_df['text'].apply(lambda x: jieba.lcut(x))\n",
        "dev_df['ckip_ws'] = dev_df['text'].apply(lambda x: jieba.lcut(x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LBvwdp9FnvKw",
        "outputId": "f91b30b7-4667-4d45-8ff9-48acc10ca28e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Loading model from cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Loading model from cache /tmp/jieba.cache\n",
            "Loading model cost 1.212 seconds.\n",
            "DEBUG:jieba:Loading model cost 1.212 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['ckip_ws'] = train_df['ckip_ws'].apply(lambda x: \" \".join(x))\n",
        "test_df['ckip_ws'] = test_df['ckip_ws'].apply(lambda x: \" \".join(x))\n",
        "dev_df['ckip_ws'] = dev_df['ckip_ws'].apply(lambda x: \" \".join(x))"
      ],
      "metadata": {
        "id": "J8xvCut8oyfg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.reset_index(drop=True, inplace=True)\n",
        "dev_df.reset_index(drop=True, inplace=True)\n",
        "dev_df.reset_index(drop=True, inplace=True)"
      ],
      "metadata": {
        "id": "v5b17wR2VRzY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import LSTM, Activation, Dense, Dropout, Input, Embedding\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing import sequence\n",
        "from keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "q6x4LLk-UyA7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "0r9QFyWZWIOg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = train_df.ckip_ws\n",
        "dev_X = dev_df.ckip_ws\n",
        "test_X = test_df.ckip_ws\n",
        "\n",
        "y_encoder = LabelEncoder()\n",
        "\n",
        "train_y = y_encoder.fit_transform(train_df.score).reshape(-1, 1)\n",
        "dev_y = y_encoder.transform(dev_df.score).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "AV2XmiD9U07q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_WORDS = 20_000\n",
        "MAX_LEN = train_df.ckip_ws.str.split(\" \").apply(lambda x: len(x)).max()\n",
        "tokenizer = Tokenizer(num_words = MAX_WORDS,\n",
        "                      lower=True)\n",
        "tokenizer.fit_on_texts(train_X)"
      ],
      "metadata": {
        "id": "ViscpJBYkW1l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences = tokenizer.texts_to_sequences(train_X)\n",
        "dev_sequences = tokenizer.texts_to_sequences(dev_X)\n",
        "test_sequences = tokenizer.texts_to_sequences(test_X)"
      ],
      "metadata": {
        "id": "nhQ8UYpXl2jD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sequences_matrix = sequence.pad_sequences(train_sequences,\n",
        "                                          maxlen=MAX_LEN)\n",
        "dev_sequences_matrix = sequence.pad_sequences(dev_sequences,\n",
        "                                          maxlen=MAX_LEN)\n",
        "test_sequences_matrix = sequence.pad_sequences(test_sequences,\n",
        "                                          maxlen=MAX_LEN)"
      ],
      "metadata": {
        "id": "QS21E9F9pRw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Bidirectional\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "2zc2UUlLwWBv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def LSTM_CLS_MODEL():\n",
        "    inputs = Input(name='inputs',shape=[MAX_LEN])\n",
        "    layer = Embedding(input_dim=MAX_WORDS,\n",
        "          output_dim=128,\n",
        "          input_length=MAX_LEN)(inputs)\n",
        "\n",
        "    layer = Bidirectional(LSTM(64, return_sequences=True))(layer)\n",
        "    layer = Bidirectional(LSTM(32, return_sequences=True))(layer)\n",
        "    layer = Bidirectional(LSTM(16, return_sequences=True))(layer)\n",
        "    # layer = Bidirectional(LSTM(8, return_sequences=True))(layer)\n",
        "\n",
        "    layer = Flatten()(layer)\n",
        "    layer = Dense(1024,\n",
        "                  name='FC1')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    # layer = BatchNormalization()(layer)\n",
        "    layer = Dropout(0.3)(layer)\n",
        "\n",
        "    layer = Dense(512,\n",
        "                  name='FC2')(layer)\n",
        "    layer = Activation('relu')(layer)\n",
        "    # layer = BatchNormalization()(layer)\n",
        "    layer = Dropout(0.3)(layer)\n",
        "\n",
        "    layer = Dense(5,\n",
        "                  name='output_layer')(layer)\n",
        "    layer = Activation('softmax')(layer)\n",
        "\n",
        "    model = Model(inputs=inputs,\n",
        "                  outputs=layer)\n",
        "    return model"
      ],
      "metadata": {
        "id": "v6qNmAFqqVLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM_CLS_MODEL()"
      ],
      "metadata": {
        "id": "8sGrPvirxWno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "2UCWEjt4yBZ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.optimizers import AdamW"
      ],
      "metadata": {
        "id": "3wWpUWBeywgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
      ],
      "metadata": {
        "id": "umtx7LgkzDdD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import mlflow.tensorflow\n",
        "# mlflow.tensorflow.autolog()\n",
        "\n",
        "# mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")\n",
        "\n",
        "# # Create a new MLflow Experiment\n",
        "# mlflow.set_experiment(\"MLflow Quickstart\")"
      ],
      "metadata": {
        "id": "xrtmuV0Nzaq3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=AdamW(0.001),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# train model\n",
        "# run = mlflow.start_run()\n",
        "model.fit(train_sequences_matrix,\n",
        "          train_y,\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          validation_data=(dev_sequences_matrix,\n",
        "                           dev_y),\n",
        "          callbacks=[EarlyStopping(monitor='val_loss',\n",
        "                                   min_delta=0.0001,\n",
        "                                   restore_best_weights=True),\n",
        "                    #  mlflow.keras.MlflowCallback(run)\n",
        "                     ]\n",
        "          )\n",
        "# mlflow.end_run()"
      ],
      "metadata": {
        "id": "tDWVGDdqyIWU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(dev_sequences_matrix, dev_y)"
      ],
      "metadata": {
        "id": "w0eTjd5H91qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(test_sequences_matrix)\n",
        "y_pred = y_encoder.inverse_transform(np.argmax(y_pred, axis=1))"
      ],
      "metadata": {
        "id": "0bRru14639sY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission_file = test_df.copy()\n",
        "submission_file['pred'] = y_pred\n",
        "submission_file = submission_file[['index', 'pred']]\n",
        "submission_file.to_csv('submission.csv', index=False)"
      ],
      "metadata": {
        "id": "xwcCn-9J8FHj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}